{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capstone_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9GibCaXjk8c",
        "outputId": "19f9844d-f0ca-4e72-c021-d8d15e667a8d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "label_dict={\"Elephant\":0,\n",
        "\"Leopard\":1,\n",
        "\"Pig\":2,\n",
        "\"Monkey\":3,\n",
        "\"Deer\":4,\n",
        "\"Jaguar\":5,\n",
        "\"Rhinoceros\":6,\n",
        "\"Snake\":7,\n",
        "\"Tiger\":8,\n",
        "\"Fox\":9,\n",
        "\"Bear\":10,\n",
        "\"Crocodile\":11\n",
        "}\n",
        "dir_path = \"/content/drive/MyDrive/Capstone_Dataset\"\n",
        "data=[]\n",
        "label_arr=[]\n",
        "for filename1 in os.listdir(dir_path):\n",
        "  for filename in os.listdir(\"/content/drive/MyDrive/Capstone_Dataset/\"+filename1):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image = cv2.imread(\"/content/drive/MyDrive/Capstone_Dataset/\"+filename1+\"/\"+filename)\n",
        "        #print(image)\n",
        "        img_size=(224,224)\n",
        "        resized = cv2.resize(image,img_size)\n",
        "        data.append(resized)\n",
        "        label_arr.append(label_dict[filename1])\n",
        "        #print(resized)"
      ],
      "metadata": {
        "id": "a0IghmSej3fm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import save\n",
        "data_np=np.array(data)\n",
        "label_np=np.array(label_arr)\n",
        "save('data_np.npy', data_np)\n",
        "save('label_np.npy',label_np)\n"
      ],
      "metadata": {
        "id": "VkiGx4PrwmKZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMuPdX5P5GQr"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "# don't train existing weights\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "\n",
        "  \n",
        "# useful for getting number of classes\n",
        "# folders = glob('/content/drive/My Drive/train/*')\n",
        "# print(folders)\n",
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n",
        "# x = Dense(1000, activation='relu')(x)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "\n",
        "# view the structure of the model\n",
        "model.summary()\n",
        "\n",
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLJdEJo94-O5"
      },
      "source": [
        "data=np.load('/content/drive/My Drive/data_np.npy')\n",
        "target=np.load('/content/drive/My Drive/label_np.npy')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data,test_data,train_target,test_target=train_test_split(data,target,test_size=0.1)\n",
        "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
        "history=model.fit(train_data,train_target,epochs=20,callbacks=[checkpoint],validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftbEl8Pm6ECv"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save(\"forestanimal_detection_model\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z7KBxlkTjmvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}